version: '3.8'
services:
  postgres:
    image: postgres:14
    env_file:
    - .env
    container_name: gemeente_postgres
    restart: always
    environment:
      POSTGRES_MULTIPLE_DATABASES: airflow,keycloak,datahub,superset
      POSTGRES_USER: gemeente
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-gemeente123}
    ports:
    - 20432:5432
    volumes:
    - postgres_data:/var/lib/postgresql/data
    - ./init-scripts:/docker-entrypoint-initdb.d
    networks:
    - backend
    healthcheck:
      test:
      - CMD-SHELL
      - pg_isready -U gemeente
      interval: 30s
      timeout: 20s
      retries: 5
  
  postgres-init:
    image: busybox
    container_name: gemeente_postgres-init
    volumes:
    - ./init-scripts:/init-scripts
    command: 'sh -c " mkdir -p /init-scripts && cat > /init-scripts/init-databases.sql
      << ''EOF'' -- Create users CREATE USER airflow WITH PASSWORD ''${AIRFLOW_DB_PASSWORD:-airflow123}'';
      CREATE USER keycloak WITH PASSWORD ''${KEYCLOAK_DB_PASSWORD:-keycloak123}'';
      CREATE USER superset WITH PASSWORD ''${SUPERSET_DB_PASSWORD:-superset123}'';
      CREATE USER datahub WITH PASSWORD ''${DATAHUB_DB_PASSWORD:-datahub123}'';

      -- Create databases CREATE DATABASE airflow; CREATE DATABASE keycloak; CREATE
      DATABASE superset; CREATE DATABASE datahub;

      -- Grant privileges GRANT ALL PRIVILEGES ON DATABASE airflow TO airflow; GRANT
      ALL PRIVILEGES ON DATABASE keycloak TO keycloak; GRANT ALL PRIVILEGES ON DATABASE
      superset TO superset; GRANT ALL PRIVILEGES ON DATABASE datahub TO datahub; EOF
      "
      '
  
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: gemeente_pgadmin
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@gemeente.nl
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD:-admin123}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
      PGADMIN_CONFIG_ENHANCED_COOKIE_PROTECTION: 'False'
    ports:
    - 8081:80
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
    - pgadmin_data:/var/lib/pgadmin
    networks:
    - backend
  
  minio:
    image: minio/minio:latest
    container_name: gemeente_minio
    restart: always
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin123}
      MINIO_BROWSER_REDIRECT_URL: http://192.168.1.25:9001
    ports:
    - 9001:9001
    - 9002:9000
    volumes:
    - minio_data:/data
    networks:
    - backend
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:9000/minio/health/live
      interval: 30s
      timeout: 20s
      retries: 3
  
  minio-init:
    image: minio/mc:latest
    container_name: gemeente_minio-init
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin123}
    entrypoint: '/bin/sh -c " mc alias set minio http://minio:9000 minioadmin $${MINIO_ROOT_PASSWORD};
      mc mb minio/datalake --ignore-existing; mc mb minio/airflow-logs --ignore-existing;
      mc mb minio/spark-warehouse --ignore-existing; mc mb minio/nifi-flowfiles --ignore-existing;
      mc policy set download minio/datalake; exit 0; "
      '
    networks:
    - backend
  
  keycloak:
    image: quay.io/keycloak/keycloak:23.0
    container_name: gemeente_keycloak
    restart: always
    command: start-dev
    environment:
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://gemeente_postgres:5432/keycloak
      KC_DB_USERNAME: keycloak
      KC_DB_PASSWORD: ${KEYCLOAK_DB_PASSWORD:-keycloak123}
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD:-admin123}
      KC_HEALTH_ENABLED: 'true'
      KC_METRICS_ENABLED: 'true'
      KC_HOSTNAME: 192.168.1.25
      KC_HOSTNAME_PORT: 8085
      KC_HOSTNAME_STRICT: 'false'
      KC_PROXY: edge
    ports:
    - 8085:8080
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
    - keycloak_data:/opt/keycloak/data
    - ./keycloak-themes:/opt/keycloak/themes
    networks:
    - backend
    healthcheck:
      test:
      - CMD-SHELL
      - "exec 3<>/dev/tcp/127.0.0.1/8080;echo -e 'GET /health/ready HTTP/1.1\r\nhost:\
        \ 127.0.0.1:8080\r\nConnection: close\r\n\r\n' >&3;cat <&3 | grep -q '200\
        \ OK'"
      interval: 30s
      timeout: 3s
      retries: 3
  
  oauth2-proxy:
    image: quay.io/oauth2-proxy/oauth2-proxy:v7.5.1
    container_name: gemeente_oauth2_proxy
    restart: always
    depends_on:
      keycloak:
        condition: service_healthy
    command:
      - --http-address=0.0.0.0:4180
      - --provider=keycloak-oidc
      - --client-id=gemeente-platform
      - --client-secret=gemeente-client-secret-change-me
      - --redirect-url=http://192.168.1.25:4180/oauth2/callback
      - --oidc-issuer-url=http://192.168.1.25:8085/realms/gemeente
      - --cookie-secret=12345678901234567890123456789012
      - --cookie-secure=false
      - --email-domain=*
      - --skip-provider-button=false
      - --pass-basic-auth=true
      - --pass-user-headers=true
      - --set-xauthrequest=true
      - --oidc-extra-audience=account
      - --upstream=http://gemeente_prometheus:9090/
    ports:
      - 4180:4180
    networks:
      - backend
  
  vault:
    image: hashicorp/vault:1.15
    container_name: gemeente_vault
    restart: always
    cap_add:
    - IPC_LOCK
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_ROOT_TOKEN:-myroot}
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
      VAULT_ADDR: http://0.0.0.0:8200
    ports:
    - 8200:8200
    volumes:
    - vault_data:/vault/data
    networks:
    - backend
  

  redis:
    image: redis:7-alpine
    container_name: gemeente_redis
    restart: always
    command: redis-server --requirepass ${REDIS_PASSWORD:-redis123}
    ports:
    - 20379:6379
    volumes:
    - redis_data:/data
    networks:
    - backend
    healthcheck:
      test:
      - CMD
      - redis-cli
      - -a
      - ${REDIS_PASSWORD:-redis123}
      - ping
      interval: 10s
      timeout: 5s
      retries: 5
  
  spark-master:
    image: bitnami/spark:3.5
    container_name: gemeente_spark-master
    restart: always
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: 'no'
      SPARK_RPC_ENCRYPTION_ENABLED: 'no'
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: 'no'
      SPARK_SSL_ENABLED: 'no'
      SPARK_USER: spark
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
    ports:
    - 28080:8080
    - 27077:7077
    volumes:
    - spark_data:/opt/bitnami/spark
    networks:
    - backend
    healthcheck:
      test:
      - CMD-SHELL
      - curl -f http://localhost:8080/ || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
  
  spark-worker:
    image: bitnami/spark:3.5
    container_name: gemeente_spark-worker
    restart: always
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2G
      SPARK_WORKER_CORES: 2
      SPARK_RPC_AUTHENTICATION_ENABLED: 'no'
      SPARK_RPC_ENCRYPTION_ENABLED: 'no'
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: 'no'
      SPARK_SSL_ENABLED: 'no'
      SPARK_USER: spark
    depends_on:
    - spark-master
    volumes:
    - spark_data:/opt/bitnami/spark/work
    networks:
    - backend
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
  
  etcd:
    image: bitnami/etcd:3.5.17
    container_name: gemeente_etcd
    restart: always
    environment:
      ALLOW_NONE_AUTHENTICATION: 'yes'
      ETCD_ROOT_PASSWORD: ${ETCD_PASSWORD:-etcd123}
      ETCD_ADVERTISE_CLIENT_URLS: http://gemeente_etcd:2379
      ETCD_LISTEN_CLIENT_URLS: http://0.0.0.0:2379
    ports:
    - 2379:2379
    volumes:
    - etcd_data:/bitnami/etcd
    networks:
    - backend
  
  apisix:
    image: apache/apisix:3.11.0-debian
    container_name: gemeente_apisix
    restart: always
    depends_on:
    - etcd
    volumes:
    - ./apisix_conf/config.yaml:/usr/local/apisix/conf/config.yaml:ro
    ports:
    - 9080:9080
    - 29443:9443
    networks:
    - backend
  
  apisix-dashboard:
    image: apache/apisix-dashboard:3.0.1-alpine
    container_name: gemeente_apisix-dashboard
    restart: always
    depends_on:
    - etcd
    environment:
      APISIX_DASHBOARD_USER: admin
      APISIX_DASHBOARD_PASSWORD: ${APISIX_ADMIN_PASSWORD:-admin123}
    volumes:
    - ./dashboard_conf/conf.yaml:/usr/local/apisix-dashboard/conf/conf.yaml:ro
    ports:
    - 9000:9000
    networks:
    - backend
  
  dashboard:
    image: nginx:alpine
    container_name: gemeente_dashboard
    restart: always
    ports:
    - 8888:80
    volumes:
    - ./dashboard.html:/usr/share/nginx/html/index.html:ro
    - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
    networks:
    - backend
  
  superset-init:
    image: apache/superset:3.0.0
    container_name: gemeente_superset-init
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      SUPERSET_CONFIG_PATH: /app/superset_config.py
      SECRET_KEY: ${SUPERSET_SECRET_KEY:-ThisIsASecureKeyForDevelopment2024ChangeInProduction}
      SUPERSET_ADMIN_PASSWORD: ${SUPERSET_ADMIN_PASSWORD:-admin123}
    volumes:
    - ./superset_config.py:/app/superset_config.py:ro
    command: 'bash -c " pip install psycopg2-binary authlib && superset db upgrade
      && superset fab create-admin --username admin --firstname Admin --lastname User
      --email admin@gemeente.nl --password ${SUPERSET_ADMIN_PASSWORD:-admin123} ||
      true && superset init"
      '
    networks:
    - backend
  
  superset:
    image: apache/superset:3.0.0
    container_name: gemeente_superset
    restart: always
    environment:
      SUPERSET_CONFIG_PATH: /app/superset_config.py
      SECRET_KEY: ${SUPERSET_SECRET_KEY:-ThisIsASecureKeyForDevelopment2024ChangeInProduction}
      SUPERSET_LOAD_EXAMPLES: 'false'
    ports:
    - 8088:8088
    depends_on:
      superset-init:
        condition: service_completed_successfully
    volumes:
    - ./superset_config.py:/app/superset_config.py:ro
    - superset_home:/app/superset_home
    networks:
    - backend
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:8088/health
      interval: 30s
      timeout: 30s
      retries: 3
  
  prometheus:
    image: prom/prometheus:latest
    container_name: gemeente_prometheus
    restart: always
    command:
    - --config.file=/etc/prometheus/prometheus.yml
    - --storage.tsdb.path=/prometheus
    - --web.console.libraries=/etc/prometheus/console_libraries
    - --web.console.templates=/etc/prometheus/consoles
    - --storage.tsdb.retention.time=200h
    - --web.enable-lifecycle
    expose:
    - '9090'
    volumes:
    - ./prometheus.yml:/etc/prometheus/prometheus.yml
    - prometheus_data:/prometheus
    networks:
    - backend
  
  grafana:
    image: grafana/grafana:latest
    container_name: gemeente_grafana
    restart: always
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin123}
      GF_USERS_ALLOW_SIGN_UP: 'false'
      GF_INSTALL_PLUGINS: grafana-piechart-panel,redis-datasource
      GF_AUTH_GENERIC_OAUTH_ENABLED: 'true'
      GF_AUTH_GENERIC_OAUTH_NAME: Keycloak
      GF_AUTH_GENERIC_OAUTH_ALLOW_SIGN_UP: 'true'
      GF_AUTH_GENERIC_OAUTH_CLIENT_ID: grafana
      GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET: ${GRAFANA_CLIENT_SECRET:-grafana-client-secret}
      GF_AUTH_GENERIC_OAUTH_SCOPES: openid email profile
      GF_AUTH_GENERIC_OAUTH_AUTH_URL: http://192.168.1.25:8085/realms/gemeente/protocol/openid-connect/auth
      GF_AUTH_GENERIC_OAUTH_TOKEN_URL: http://192.168.1.25:8085/realms/gemeente/protocol/openid-connect/token
      GF_AUTH_GENERIC_OAUTH_API_URL: http://192.168.1.25:8085/realms/gemeente/protocol/openid-connect/userinfo
      GF_AUTH_SIGNOUT_REDIRECT_URL: http://192.168.1.25:8085/realms/gemeente/protocol/openid-connect/logout?redirect_uri=http://192.168.1.25:13000
      GF_SERVER_ROOT_URL: http://192.168.1.25:13000
    ports:
    - 13000:3000
    volumes:
    - grafana_data:/var/lib/grafana
    - ./grafana/provisioning:/etc/grafana/provisioning
    networks:
    - backend
    depends_on:
    - prometheus
  
  loki:
    image: grafana/loki:latest
    container_name: gemeente_loki
    restart: always
    expose:
    - '3100'
    volumes:
    - ./loki-config.yml:/etc/loki/local-config.yaml:ro
    - loki_data:/loki
    networks:
    - backend
    command: -config.file=/etc/loki/local-config.yaml
  
  promtail:
    image: grafana/promtail:latest
    container_name: gemeente_promtail
    restart: always
    volumes:
    - ./promtail-config.yml:/etc/promtail/config.yml
    - /var/log:/var/log:ro
    - /var/lib/docker/containers:/var/lib/docker/containers:ro
    networks:
    - backend
    depends_on:
    - loki
  
  neo4j:
    image: neo4j:4.4-community
    container_name: gemeente_neo4j
    restart: always
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD:-datahub123}
      NEO4J_dbms_default__database: graph.db
      NEO4J_dbms_allow__upgrade: 'true'
    ports:
    - 7474:7474
    - 7687:7687
    volumes:
    - neo4j_data:/data
    networks:
    - backend
    healthcheck:
      test:
      - CMD-SHELL
      - wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
  
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.18
    container_name: gemeente_elasticsearch
    restart: always
    environment:
      discovery.type: single-node
      xpack.security.enabled: 'true'
      xpack.security.authc.api_key.enabled: 'true'
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-elastic123}
      ES_JAVA_OPTS: -Xms512m -Xmx512m
    expose:
    - '9200'
    volumes:
    - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
    - backend
    healthcheck:
      test:
      - CMD-SHELL
      - curl -f -u elastic:${ELASTIC_PASSWORD:-elastic123} http://localhost:9200/_cluster/health
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
  
  httpbin:
    image: kennethreitz/httpbin
    container_name: gemeente_httpbin
    restart: always
    ports:
    - 18080:80
    networks:
    - backend

# Volumes definitie
volumes:
  postgres_data:
  pgadmin_data:
  superset_home:
  minio_data:
  keycloak_data:
  vault_data:
  redis_data:
  spark_data:
  etcd_data:
  prometheus_data:
  grafana_data:
  loki_data:
  neo4j_data:
  elasticsearch_data:

# Networks definitie
networks:
  backend:
    driver: bridge