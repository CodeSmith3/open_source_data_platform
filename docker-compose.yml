# Airflow common settings
x-airflow-common:
  &airflow-common
  image: apache/airflow:2.8.1-python3.11
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:${AIRFLOW_DB_PASSWORD:-airflow123}@gemeente_postgres:5432/airflow
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY:-Zv8-bGq6UQ_B0K8eQf7WEjPfzKXyUJrSCxP9vXzjZIs=}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__DEFAULT_TIMEZONE: Europe/Amsterdam
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
    AIRFLOW__WEBSERVER__RBAC: 'true'
    AIRFLOW__WEBSERVER__BASE_URL: http://localhost:8082
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    AIRFLOW_CONN_POSTGRES_DEFAULT: postgresql://gemeente:${POSTGRES_PASSWORD:-gemeente123}@gemeente_postgres:5432/gemeente
    AIRFLOW_CONN_MINIO_DEFAULT: aws://minioadmin:${MINIO_ROOT_PASSWORD:-minioadmin123}@?host=http://gemeente_minio:9000&region_name=us-east-1
    PYTHONPATH: /opt/airflow
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./config:/opt/airflow/config
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    &airflow-common-depends-on
    postgres:
      condition: service_healthy

services:
  # ===================================
  # CORE INFRASTRUCTURE
  # ===================================
  
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: gemeente_postgres
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-gemeente}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-gemeente123}
      POSTGRES_MULTIPLE_DATABASES: gemeente,superset,airflow,keycloak
    ports:
      - "20432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U gemeente"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: gemeente_redis
    restart: always
    ports:
      - "20379:6379"
    command: redis-server --requirepass ${REDIS_PASSWORD:-redis123}
    volumes:
      - redis_data:/data
    networks:
      - backend
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ===================================
  # STORAGE
  # ===================================
  
  minio:
    image: minio/minio:latest
    container_name: gemeente_minio
    restart: always
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin123}
    command: server /data --console-address ":9001"
    ports:
      - "9002:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    networks:
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3

  minio-init:
    image: minio/mc:latest
    container_name: gemeente_minio_init
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      sleep 10;
      /usr/bin/mc config host add myminio http://gemeente_minio:9000 minioadmin minioadmin123;
      /usr/bin/mc mb myminio/airflow-logs --ignore-existing;
      /usr/bin/mc mb myminio/data-lake --ignore-existing;
      /usr/bin/mc mb myminio/qgis-projects --ignore-existing;
      exit 0;
      "
    networks:
      - backend

  # ===================================
  # SECURITY
  # ===================================
  
  keycloak:
    image: quay.io/keycloak/keycloak:23.0
    container_name: gemeente_keycloak
    restart: always
    environment:
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://gemeente_postgres:5432/keycloak
      KC_DB_USERNAME: ${POSTGRES_USER:-gemeente}
      KC_DB_PASSWORD: ${POSTGRES_PASSWORD:-gemeente123}
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD:-admin123}
      KC_HOSTNAME_STRICT: 'false'
      KC_HTTP_ENABLED: 'true'
      KC_PROXY: edge
    command: start-dev
    ports:
      - "8085:8080"
    volumes:
      - keycloak_data:/opt/keycloak/data
    networks:
      - backend
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 5

  vault:
    image: hashicorp/vault:latest
    container_name: gemeente_vault
    restart: always
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_ROOT_TOKEN:-myroot}
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
    cap_add:
      - IPC_LOCK
    ports:
      - "8200:8200"
    volumes:
      - vault_data:/vault/data
    networks:
      - backend
    command: server -dev

  # ===================================
  # API GATEWAY - APISIX
  # ===================================
  
  etcd:
    image: quay.io/coreos/etcd:v3.5.9
    container_name: gemeente_etcd
    restart: always
    environment:
      ETCD_ENABLE_V2: "true"
      ALLOW_NONE_AUTHENTICATION: "yes"
      ETCD_ADVERTISE_CLIENT_URLS: "http://gemeente_etcd:2379"
      ETCD_LISTEN_CLIENT_URLS: "http://0.0.0.0:2379"
    ports:
      - "2379:2379"
      - "2380:2380"
    volumes:
      - etcd_data:/etcd-data
    networks:
      - backend
    command: 
      - /usr/local/bin/etcd
      - --data-dir=/etcd-data
      - --name=node1
      - --initial-advertise-peer-urls=http://gemeente_etcd:2380
      - --listen-peer-urls=http://0.0.0.0:2380
      - --advertise-client-urls=http://gemeente_etcd:2379
      - --listen-client-urls=http://0.0.0.0:2379
      - --initial-cluster=node1=http://gemeente_etcd:2380

  apisix:
    image: apache/apisix:3.7.0-debian
    container_name: gemeente_apisix
    restart: always
    volumes:
      - ./apisix_conf/config.yaml:/usr/local/apisix/conf/config.yaml:ro
    ports:
      - "9080:9080"
      - "9443:9443"
    networks:
      - backend
    depends_on:
      - etcd
    environment:
      APISIX_STAND_ALONE: "false"

  apisix-dashboard:
    image: apache/apisix-dashboard:3.0.1-alpine
    container_name: gemeente_apisix_dashboard
    restart: always
    volumes:
      - ./dashboard_conf/conf.yaml:/usr/local/apisix-dashboard/conf/conf.yaml:ro
    ports:
      - "9000:9000"
    networks:
      - backend
    depends_on:
      - etcd

  # ===================================
  # BI & ANALYTICS
  # ===================================
  
  superset:
    image: apache/superset:latest
    container_name: gemeente_superset
    restart: always
    environment:
      SUPERSET_SECRET_KEY: ${SUPERSET_SECRET_KEY:-your-secret-key-change-in-production}
      SUPERSET_LOAD_EXAMPLES: 'no'
      POSTGRES_DB: superset
      POSTGRES_USER: ${POSTGRES_USER:-gemeente}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-gemeente123}
      POSTGRES_HOST: gemeente_postgres
      POSTGRES_PORT: 5432
    ports:
      - "8088:8088"
    volumes:
      - superset_home:/app/superset_home
      - ./superset_config.py:/app/pythonpath/superset_config.py
    networks:
      - backend
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  superset-init:
    image: apache/superset:latest
    container_name: gemeente_superset-init
    command: >
      bash -c "
      superset db upgrade &&
      superset fab create-admin --username admin --firstname Admin --lastname User --email admin@gemeente.nl --password ${SUPERSET_ADMIN_PASSWORD:-admin123} &&
      superset init
      "
    environment:
      SUPERSET_SECRET_KEY: ${SUPERSET_SECRET_KEY:-your-secret-key-change-in-production}
      POSTGRES_DB: superset
      POSTGRES_USER: ${POSTGRES_USER:-gemeente}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-gemeente123}
      POSTGRES_HOST: gemeente_postgres
      POSTGRES_PORT: 5432
    volumes:
      - superset_home:/app/superset_home
      - ./superset_config.py:/app/pythonpath/superset_config.py
    networks:
      - backend
    depends_on:
      postgres:
        condition: service_healthy

  # ===================================
  # GIS - QGIS SERVER
  # ===================================
  
  qgis-server:
    image: camptocamp/qgis-server:3.28
    container_name: gemeente_qgis_server
    restart: always
    environment:
      QGIS_SERVER_LOG_LEVEL: 0
      QGIS_SERVER_LOG_STDERR: 1
      QGIS_PROJECT_FILE: /projects/project.qgs
      PGSERVICEFILE: /etc/pg_service.conf
      POSTGRES_HOST: gemeente_postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: gemeente
      POSTGRES_USER: ${POSTGRES_USER:-gemeente}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-gemeente123}
    ports:
      - "8090:80"
    volumes:
      - qgis_projects:/projects
      - qgis_data:/data
    networks:
      - backend
    depends_on:
      - postgres
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/qgis/wms?SERVICE=WMS&VERSION=1.3.0&REQUEST=GetCapabilities"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===================================
  # AIRFLOW - DATA ORCHESTRATION
  # ===================================
  
  airflow-init:
    <<: *airflow-common
    container_name: gemeente_airflow_init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        pip install --no-cache-dir \
          apache-airflow-providers-postgres \
          apache-airflow-providers-amazon \
          authlib \
          flask-openid
        
        airflow db migrate
        
        airflow users create \
          --username admin \
          --password ${AIRFLOW_ADMIN_PASSWORD:-admin123} \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@gemeente.nl || true
        
        echo "Airflow initialization complete!"
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
    networks:
      - backend

  airflow-webserver:
    <<: *airflow-common
    container_name: gemeente_airflow_webserver
    command: webserver
    ports:
      - "8082:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    networks:
      - backend
    environment:
      <<: *airflow-common-env

  airflow-scheduler:
    <<: *airflow-common
    container_name: gemeente_airflow_scheduler
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    networks:
      - backend
    environment:
      <<: *airflow-common-env

  # ===================================
  # ADMIN TOOLS
  # ===================================
  
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: gemeente_pgadmin
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL:-admin@gemeente.nl}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD:-admin123}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
      PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED: 'False'
    ports:
      - "8081:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    networks:
      - backend
    depends_on:
      - postgres

  # ===================================
  # MONITORING
  # ===================================
  
  prometheus:
    image: prom/prometheus:latest
    container_name: gemeente_prometheus
    restart: always
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - backend

  grafana:
    image: grafana/grafana:latest
    container_name: gemeente_grafana
    restart: always
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin123}
      GF_USERS_ALLOW_SIGN_UP: 'false'
      GF_INSTALL_PLUGINS: grafana-piechart-panel,redis-datasource
      GF_SERVER_ROOT_URL: http://localhost:13000
    ports:
      - "13000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    networks:
      - backend
    depends_on:
      - prometheus

  loki:
    image: grafana/loki:latest
    container_name: gemeente_loki
    restart: always
    ports:
      - "3100:3100"
    volumes:
      - ./loki-config.yml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    networks:
      - backend
    command: -config.file=/etc/loki/local-config.yaml

  promtail:
    image: grafana/promtail:latest
    container_name: gemeente_promtail
    restart: always
    volumes:
      - ./promtail-config.yml:/etc/promtail/config.yml
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    networks:
      - backend
    depends_on:
      - loki

# ===================================
# VOLUMES
# ===================================

volumes:
  postgres_data:
  pgadmin_data:
  superset_home:
  minio_data:
  keycloak_data:
  vault_data:
  redis_data:
  etcd_data:
  prometheus_data:
  grafana_data:
  loki_data:
  airflow_logs:
  airflow_plugins:
  qgis_projects:
  qgis_data:

# ===================================
# NETWORKS
# ===================================

networks:
  backend:
    external: true
    name: gemeente_data_platform_dev_backend